{
    "TÃ­tulo": "Haystack Home Page",
    "Cuerpo": "Date: Mon, 25 Nov 1996 23:59:43 GMT Server: Apache/1.2-dev Connection: close Content-Type: text/html Expires: Mon, 25 Nov 1996 23:59:43 GMT Last-Modified: Fri, 30 Aug 1996 19:35:47 GMT ETag: \"c99de-21f5-32274293\" Content-Length: 8693 Accept-Ranges: bytes Haystack Home Page The internal Haystack page has moved. This public page is under construction. A few systems, such as Harvest or Content Routing, have attempted to address the gaps between these two extremes, focusing on the construction of a more flexible substrate which allows users and communities to build their own repositories or queries. The Haystack project is aimed at the individual customization end of these more realistic ``living'' information retrieval systems. We are interested in building on customizable substrates, such as those provided by Harvest or Content Routing, to create a community of individual but interacting ``haystacks'': personal information repositories which archive not only base content but also user-specific meta-information, enabling them to adapt to the particular needs of their users. We believe that such a system will let us address several questions: How can individuals use an information retrieval system to organize their own personal collection of information? As individuals build up their own collections and information retrieval systems, how can they search for information that might be located in others' collections, especially when such information is organized by information retrieval systems that may differ greatly from their own? Our first step towards this goal has been to design a simple and convenient user interface to and annotation format for an information retrieval system. The annotations themselves are first-class documents in our system, so that, for example, search information can be reified and treated as an indexable object. In our implementation, we have chosen to detach the information retrieval ``engine'' from the user interface and annotation system, specifying only that the engine should accept a natural language query and return documents that ``match'' under whatever criteria it uses. Once the system is in use, we will be able to leverage the annotation facilities to explore several questions. Do they tend to be over-precise and find no documents, or do they overgeneralize and get swamped with useless results? What refinement strategies do they use? A second question is how a system might learn from interaction with its user. For the future, the system should learn that when the user types a query like Q , document D is likely to be relevant even if it does not appear to be a good match. The system might annotate a document with terms that do not appear in it but that the user types when he expects to find that document. Given that individuals are organizing the information they care about, it is natural to ask how one user can benefit from the work of other users. Both to limit the costs of a search and to improve the filtering of what is returned, it is important for the system to learn over time which other individuals are most likely to have information that a given user finds relevant---these haystack ``neighbors'' are the systems that should be queried first and whose results should be most trusted. Another opportunity that this linking of haystacks creates is in connecting individuals to other people who can address their information need. By developing the Haystack system, we will attract the community of users who will provide the necessary testbed for exploring these questions about evolving, interacting customized information systems.",
    "ground_truth": "project"
}