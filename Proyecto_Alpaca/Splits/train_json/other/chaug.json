{
    "TÃ­tulo": "Machine Learning Papers and Abstracts",
    "Cuerpo": "Inductive Logic Programming for Natural Language Processing Raymond J. Mooney Proceedings of the 6th International Inductive Logic Programming Workshop , pp. Integrating EBL and ILP to Acquire Control Rules for Planning Tara A. Estlin and Raymond J. Mooney Proceedings of the Third International Workshop on Multi-Strategy Learning , pp. This paper presents a novel learning approach for control knowledge acquisition that integrates explanation-based learning with techniques from inductive logic programming. This paper presents a novel learning approach for control knowledge acquisition that integrates explanation-based learning with techniques from inductive logic programming. The first component has been implemented and we will present results from experiments on real world classification problems which show our technique to be effective. This approach has been implemented as a computer program, ASSERT, using a machine learning technique called theory refinement , which is a method for automatically revising a knowledge base to be consistent with a set of examples. This paper presents results from recent experiments with CHILL, a corpus-based parser acquisition system. This paper presents an alternative approach based on techniques from a subfield of machine learning known as inductive logic programming (ILP). This paper presents results from recent experiments with CHILL, a corpus-based parser acquisition system. In this paper, we present an approach to learning the models for such systems. We show that results of applying our technique to several examples and demonstrate that it is effective. This approach has been implemented as a computer program, ASSERT, using a machine learning technique called theory refinement which is a method for automatically revising a knowledge base to be consistent with a set of examples. (AAAI-94) A new inductive learning system, LAB (Learning for ABduction), is presented which acquires abductive rules from a set of training examples. Our approach uses recent machine learning methods for inducing Prolog rules from examples (inductive logic programming). The goal of a theory refinement learner is to modify an incomplete or incorrect rule base, representing a domain theory, to make it consistent with a set of input training examples. The results are promising: the rule base learned is simpler than the expert knowledge base and rules learned by one of the other systems, and the accuracy of the learned rule base in predicting which areas are damaged is better than all the other systems as well as the expert knowledge base. This paper presents a system, FORTE (First-Order Revision of Theories from Examples), for refining first-order Horn-clause theories. Examples of the technique are presented and experimental results are given. This method is implemented in the EITHER propositional Horn-clause theory revision system. In other words, when the data is noisy, performance on novel test data is considerably better than revising the theory to completely fit the data.",
    "ground_truth": "other"
}