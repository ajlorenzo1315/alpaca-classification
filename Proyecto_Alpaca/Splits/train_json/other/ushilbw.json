{
    "TÃ­tulo": "LESS Research Agenda",
    "Cuerpo": "MIME-Version: 1.0 Server: CERN/3.0 Date: Tuesday, 07-Jan-97 15:44:32 GMT Content-Type: text/html Content-Length: 11186 Last-Modified: Friday, 13-Dec-96 15:35:10 GMT LESS Research Agenda Laboratory for Experimental Software Systems Research Agenda The Laboratory for Experimental Software Systems (LESS) at the University of Texas at Austin's Department of Computer Sciences was formed in September 1996 by four new faculty members --- Lorenzo Alvisi , Robert Blumofe , Mike Dahlin , and Calvin Lin --- to aggregate resources and promote collaboration on research in experimental software systems, particularly in the areas of programming support and fault tolerance for cluster and web-based applications. Fault tolerant parallel computing with distributed shared memory (Alvisi and Blumofe). Prior work has shown that the combination of a \"well structured\" parallel programming model, the randomized \"work-stealing\" scheduling algorithm, and the \"dag consistency\" coherence model of distributed shared memory (a combination that form the basis for the Cilk parallel language and runtime system) yields efficient and predictable performance both in theory and in practice. We propose to use a combination of two new techniques --- \"return transactions\" and \"causal logging of reconciles\" --- that take advantage of the following key algorithmic property of the well structuring, work stealing, and dag consistency combination. In general, however, with distributed shared memory, this technique is not sufficient as it requires that all modifications to shared memory made by a stolen activation and all of its descendants are buffered to create an atomic transaction when the stolen activation returns. To avoid potentially huge amounts of buffering, causal logging of reconciles will use causal message-logging techniques to allow modifications to shared memory to be flushed (reconciled) to backing store even before the stolen activation returns. This approach has been very successful for traditional parallel platforms in which each program runs on a static set of (effectively) dedicated processors. With the growing use and acceptance of SMPs and clusters for parallel computation, however, this assumption of dedicated resources is no longer valid, and it has been shown that applications and libraries coded with static partitioning have very unreliable performance when run on non-dedicated resources. On the other hand, it has been shown that by using wait-free synchronization techniques and a dynamic partitioning (such as with work stealing), performance becomes very reliable. To make this point, we propose to code and make available a set of libraries, including BLAS, for SMPs (and later clusters) that use these techniques to deliver reliable and predictable performance on shared resources. This project seeks to provide stronger cache consistency and data update guarantees that will enable new classes of web-based applications. The system will provide a range of consistency and update options with different guarantees and different costs, and applications will pay for only the guarantees that they require. To minimize the impact on application performance and to scale the cost of our solution with the number of failures that need to be tolerated, we plan to use causal logging . Furthermore, since the file system in general cannot roll back, the application must delay output to the file system until it executes an output commit protocol, which requires synchronous logging to stable storage. Tolerating transient software-generated faults --- the so-called Heisenbugs --- through rollback-based techniques becomes more problematic as well, since frequent writes to the file system can limit the extent by which a process can roll back. To address these problems, the middleware that we plan to build will present the file system to the application not as a detached component of the external environment, but as an integrated partner that can be trusted to provide the data needed during recovery. In our solution, clients can pass dirty data directly to each other without using the file server to make the data stable. The middleware allows a client that experiences a Heisenbug to roll back past its last write to the file system, increasing the likelihood of successful recovery. Parallel computing on the world-wide web with Java (Alvisi, Blumofe, Dahlin, and Lin). This project will use Java as the basis for a new parallel computing infrastructure, to be called Jem (pronounced \"gem\") for the world-wide web.",
    "ground_truth": "other"
}