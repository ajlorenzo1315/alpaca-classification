{
    "Título": "Optimal Video Transmission",
    "Cuerpo": "MIME-Version: 1.0 Server: CERN/3.0 Date: Sunday, 01-Dec-96 20:07:04 GMT Content-Type: text/html Content-Length: 9271 Last-Modified: Thursday, 29-Feb-96 04:40:15 GMT Optimal Video Transmission Optimal Video Transmission By Mishaal Almashan Advised by Dexter Kozen MEng Project,  Fall 1995 Computer Science Department Cornell University Table of Contents Project Title Introduction Quick Overview of MPEG History Compression Algorithm MPEG Frames Motion Vectors Problem Aim of this Project Research Sources/Notes Links to Relavent Topics Demo output of current mpeg_weigh on RedsNightmare.mpg mpeg_weigh reads in an MPEG-1 video file and parses the frames to extract the motion vectors of blocks within the frames. The algorithm will be modified to take the rate of motion into account when prioritizing frames for transmission, so that frames with more motion are less likely to be dropped. An algorithm was developed that would drop the least critical frames in a video stream when the transmission bandwidth is narrow. The algorithm, described in Efficient Algorithms for Optimal Video Transmission ,   was proved to be optimal for most video,  but when it comes to video with a lot of scenery motion (as in panning and scanning) it fails. So the aim of this project is to account for the rate of motion and assign weights to the frames so as to drop the least weighted frames and still preserve perceptual continuity. It will explore and study the motion vectors in MPEG encoded video and try to determine from that how critical is the frame. Quick Overview of MPEG-1 History The Moving Pricture Expert Group (MPEG) comitee, a group under the International Standards Organization (ISO),  started it's effort to draft a standard for digital video and audio compression in 1988. Motion compensation occurs by predicting motion between 16x16 macroblocks of frames in the temporal direction (motion-vectors), then the prediction error in 8x8 macroblocks of the frames can be compresssed using the redundancy in the spatial direction with DCT. This qautization often results in the coeffecients to be zero. These coefficients, along with the motion vectors, DC components, quantization values, and other parameters are then Huffman coded using fixed tables. MPEG Frames The standards called for random access, fast forward and reverse searches, reverse playback, and audio-visual synchronization. These frames are sill images having no dependency on any other frames. Each macroblock of these P frames can come with either a vector and difference DCT coefficients of the last I or P frame,  or it can be intra coded (just like I frames). The last type of frames is the Bidirectional frame (B),  which can depend on past and future I or P frames. Backward dependency, in which a block is referenceing a block in the past Forward dependency, in which a block is referencing a block in the future Average, in which a block is the difference of the average of both a past and future block Figure O.1: MPEG Frames These dependencies are better illustrated in Figure O.1 One can see how P frames depend on past I or P frames while B frames can depend on both I or P in the future or past. So, for example,  when a frame is used as a reference for multiple frames, it would be weighted heavier than a frame with one frame dependence. Such an algorithm is optimal in the sense of data throughput,  but the aim is to have a transmission that is perceptually acceptable. Aim of this Project Knowing that MPEG video frames carry motion vectors, and that frames with more motion are perceptualy-ciritcal, we can use these vectors as motion detectors. The aim of this project is to extract the motion vectors and somehow use them to weigh the different frames. [ Table of Contents | References | Links to other Topics | CS Home Page ] © Oct, 15 1995 Mishaal Almashan Cornell University",
    "ground_truth": "other"
}