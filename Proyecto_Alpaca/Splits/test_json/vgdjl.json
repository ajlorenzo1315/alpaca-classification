{
    "TÃ­tulo": "Parallel Object Recognition and Applications to Facial Recognition\n",
    "Cuerpo": "MIME-Version: 1.0 Server: CERN/3.0 Date: Sunday, 01-Dec-96 19:52:08 GMT Content-Type: text/html Content-Length: 23087 Last-Modified: Friday, 17-May-96 02:19:39 GMT Parallel Object Recognition and Applications to Facial Recognition Parallel Object Recognition and Applications to Facial Recognition Matt Androski, Chris Paradis, & Jody Shapiro Introduction This project was an attempt to parallelize a computer vision object recognition algorithm. For this application, one of the images in the match will be a model from a stored database while the other will be region of a new image. This matrix is used to project each of the model images and any region of the new image into the subspace. The new image is subdivided into cells where each cell represents a set of translations of the model with respect to the image. Projections of regions of the new image are computed for each cell, at each level. Thus each processor would be assigned a group of cells and would search each of these cells for all models in the database. Thus each processor would have a subset of the models in the database and would search every cell in the image for its set of models. This method is much more tolerant of a large database than the first, but it introduces some significant problems. Instead it is necessary to have processors store projections in a global data structure as they are calculated so other processors can access them. Figure 4 - Load Balancing Performance Once our Split-C implementation was complete, we measured its performance on the SP-2 massively parallel processor. We didn't have access to the people who appear in our database, so we decided to create synthetic images by inserting the edge images (the ones we kept out of the database) into images which contained other faces of roughly the same size. Each pair of images following consists of the synthetic image created by inserting the face we wish to search for and the same image with the best match overlayed in red. Figure 7 - Face database Original image and edge-detected version Person 15/1 inserted at 225,10. Thus it may be possible to use the approximate Hausdorff method to quickly search the image, and then use a more robust face matching algorithm to pick the best match from the survivors. Conclusions It has been established that searching a scene for a given set of models can be conducted efficiently by using the approximation to the Hausdorff fraction. Thus, with enough processors at our disposal we can quickly search a new scene for models in the database. Given a database of faces and a scene, it is possible to use this algorithm to search the image for people who appear in the database. This would require the people in the database to naturally appear in the test images;  most likely a new face database would need to be created. The true Hausdorff fraction that is computed to eliminate matches is not necessarily the best measure to use for facial recognition. Perhaps a better method would be to use a greyscale-based matching scheme;  the method used in [3] might be a good candidate.",
    "ground_truth": "unknown"
}