{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe699a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpaca-bitcoin-sentiment-dataset.json  llama_models\t    prueba.py\r\n",
      "bitcoin-sentiment-tweets.csv\t       llama_promt_log.txt  README.md\r\n",
      "data\t\t\t\t       model\t\t    requirements.txt\r\n",
      "Error_intall.log\t\t       not_git\t\t    samples\r\n",
      "fintuning.ipynb\t\t\t       promts.log\t    tranfor_data.py\r\n",
      "get_file.py\t\t\t       prueba_2.py\t    version.md\r\n",
      "llama\t\t\t\t       prueba_3.py\r\n",
      "llama-cpp-python\t\t       prueba_4.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45c34a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Título', 'Cuerpo', 'ground_truth'])\n",
      "Título: VisComp Papers\n",
      "\n",
      "Cuerpo: Date: Thu, 21 Nov 1996 20:09:30 GMT Server: NCSA/1.5 Content-type: text/html Last-modified: Thu, 24 Aug 1995 08:39:01 GMT Content-length: 4395 VisComp Papers Ramesh Jain Director Visual Computing Laboratory University of California, San Diego 9500 Gilman Drive, Mail Code 0407 La Jolla, CA 92093-0407 Ramesh Jain is currently a Professor of Electrical and Computer Engineering , and Computer Science and Engineering at University of California, San Diego . Before joining UCSD, he was a Professor of Electrical Engineering and Computer Science , and the founding Director of the Artificial Intelligence Laboratory at the University of Michigan , Ann Arbor , MI . He has also been affiliated with Stanford University , IBM Almaden Research Labs , General Motors Research Labs, Wayne State University , University of Texas at Austin , University of Hamburg , Germany , and Indian Institute of Technology, Kharagpur , India . His current research interests are in multimedia information systems image databases, machine vision , and intelligent systems. He was the founder and the Chairman of Imageware Inc. , an Ann Arbor based company dedicated to revolutionize software interfaces for emerging sensor technologies. He is the founding chairman of Virage , a San Diego based company developing systems for visual information retrieval . Ramesh is a Fellow of IEEE , AAAI , and Society of Photo-Optical Instrumentation Engineers , and member of ACM , Pattern Recognition Society, Cognitive Science Society, Optical Society of America, and Society of Manufacturing Engineers . He has been involved in organization of several professional conferences and workshops, and served on editorial boards of many journals. Currently, he is the Editor-in-Chief of IEEE Multimedia , and is on the editorial boards of Machine Vision and Applications, Pattern Recognition, and Image and Vision Computing. He received his Ph.D. from IIT, Kharagpur in 1975 and his B.E. from Nagpur University in 1969. Arun Katkere Thu Aug 24 01:31:19 PDT 1995\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def get_file(path_file):\n",
    "    with open(path_file) as f:\n",
    "        data = json.load(f)\n",
    "    print(data.keys())\n",
    "    return ('\\n\\n').join([f\"{str(key)}: {data[key]}\" for key in data.keys() if key != 'ground_truth'])\n",
    "    \n",
    "print(get_file('./data/dummy.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c79a36",
   "metadata": {},
   "source": [
    "Intalamos las dependencias necesarias\n",
    "\n",
    "- transformers: for loading a large language model and fine-tuning it.\n",
    "\n",
    "- bitsandbytes: for loading the model in 4-bit precision.\n",
    "\n",
    "- accelerate: for training models and performing inference at scale.\n",
    "\n",
    "- peft: for fine-tuning a small number of parameters.\n",
    "\n",
    "- trl: for training transformer language models using Reinforcement Learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94339b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q accelerate==0.21.0 --progress-bar off\n",
    "!pip install -q peft==0.4.0 --progress-bar off\n",
    "!pip install -q bitsandbytes==0.40.2 --progress-bar off\n",
    "!pip install -q transformers==4.31.0 --progress-bar off\n",
    "!pip install -q trl==0.4.7 --progress-bar off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f29bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e71ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scipy --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba59964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decorator                 5.1.1\r\n",
      "rfc3339-validator         0.1.4\r\n",
      "rfc3986-validator         0.1.1\r\n",
      "torch                     2.1.0\r\n",
      "torchaudio                2.1.0\r\n",
      "torchvision               0.16.0\r\n",
      "tornado                   6.3.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep tor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e49bf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/alourido/Desktop/alpaca-classification',\n",
       " '/home/alourido/anaconda3/lib/python311.zip',\n",
       " '/home/alourido/anaconda3/lib/python3.11',\n",
       " '/home/alourido/anaconda3/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/home/alourido/anaconda3/lib/python3.11/site-packages']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab167dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva lista de directorios\n",
    "new_sys_path = [\n",
    "    '',\n",
    "    '/home/alourido/anaconda3/envs/alpaca/lib/python311.zip',\n",
    "    '/home/alourido/anaconda3/envs/alpaca/lib/python3.11',\n",
    "    '/home/alourido/anaconda3/envs/alpaca/lib/python3.11/lib-dynload',\n",
    "    '/home/alourido/anaconda3/envs/alpaca/lib/python3.11/site-packages',\n",
    "    '/home/alourido/Desktop/llama'\n",
    "]\n",
    "\n",
    "# Reemplaza sys.path con la nueva lista de directorios\n",
    "sys.path = new_sys_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ece62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8bcaf",
   "metadata": {},
   "source": [
    "A continuación, cargaremos las bibliotecas necesarias para ajustar un modelo de lenguaje grande (LLM) como Llama 2. Examinaremos cada clase importada con mayor detalle en las secciones siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126c92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randrange\n",
    "from functools import partial\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoTokenizer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          HfArgumentParser,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          EarlyStoppingCallback,\n",
    "                          pipeline,\n",
    "                          logging,\n",
    "                          set_seed)\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, AutoPeftModelForCausalLM\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3bba9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a1a5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1xQ89cpZCnafsW5T3G3ZQWvR7q682t2BN\n",
      "To: /home/alourido/Desktop/alpaca-classification/bitcoin-sentiment-tweets.csv\n",
      "100%|█████████████████████████████████████████| 242k/242k [00:01<00:00, 234kB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gdown --progress-bar off\n",
    "!gdown 1xQ89cpZCnafsW5T3G3ZQWvR7q682t2BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53dd1aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Mar 23 00:40:40 +0000 2018</td>\n",
       "      <td>@p0nd3ea Bitcoin wasn't built to live on excha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Mar 23 00:40:40 +0000 2018</td>\n",
       "      <td>@historyinflicks Buddy if I had whatever serie...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Mar 23 00:40:42 +0000 2018</td>\n",
       "      <td>@eatBCH @Bitcoin @signalapp @myWickr @Samsung ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Mar 23 00:41:04 +0000 2018</td>\n",
       "      <td>@aantonop Even if Bitcoin crash tomorrow morni...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Mar 23 00:41:07 +0000 2018</td>\n",
       "      <td>I am experimenting whether I can live only wit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date  \\\n",
       "0  Fri Mar 23 00:40:40 +0000 2018   \n",
       "1  Fri Mar 23 00:40:40 +0000 2018   \n",
       "2  Fri Mar 23 00:40:42 +0000 2018   \n",
       "3  Fri Mar 23 00:41:04 +0000 2018   \n",
       "4  Fri Mar 23 00:41:07 +0000 2018   \n",
       "\n",
       "                                               tweet  sentiment  \n",
       "0  @p0nd3ea Bitcoin wasn't built to live on excha...        1.0  \n",
       "1  @historyinflicks Buddy if I had whatever serie...        1.0  \n",
       "2  @eatBCH @Bitcoin @signalapp @myWickr @Samsung ...        0.0  \n",
       "3  @aantonop Even if Bitcoin crash tomorrow morni...        0.0  \n",
       "4  I am experimenting whether I can live only wit...        1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data='./data/bitcoin-sentiment-tweets.csv'\n",
    "df = pd.read_csv(path_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a928be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score_to_name(score: float):\n",
    "    if score > 0:\n",
    "        return \"Positive\"\n",
    "    elif score < 0:\n",
    "        return \"Negative\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "dataset_data = [\n",
    "    {\n",
    "        \"instruction\": \"Detect the sentiment of the tweet.\",\n",
    "        \"input\": row_dict[\"tweet\"],\n",
    "        \"output\": sentiment_score_to_name(row_dict[\"sentiment\"])\n",
    "    }\n",
    "    for row_dict in df.to_dict(orient=\"records\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a96ff8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Detect the sentiment of the tweet.',\n",
       " 'input': \"@p0nd3ea Bitcoin wasn't built to live on exchanges.\",\n",
       " 'output': 'Positive'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f41050a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a19dee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alpaca-bitcoin-sentiment-dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset_data, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efbccf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "897d1dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425cf0628fa64f3e960516e9841d0a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL =  \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cpu\",\n",
    "    \n",
    ")\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "tokenizer.pad_token_id = (\n",
    "    0  # unk. we want this to be different from the eos token\n",
    ")\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f03b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252df3d07e3749e684584df3ddc532bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352e61b608c44078b821ede3fd581254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d2073076444e7bb391961166f2a49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data =load_dataset(\"json\", data_files=\"alpaca-bitcoin-sentiment-dataset.json\")\n",
    "#print(dataset_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b21e4da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'instruction', 'output'],\n",
       "    num_rows: 1897\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a7bbf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd0629e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):    \n",
    "    return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.  # noqa: E501\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53b6a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(prompt, add_eos_token=True):\n",
    "    # there's probably a way to do this with the tokenizer settings\n",
    "    # but again, gotta move fast\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=CUTOFF_LEN,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < CUTOFF_LEN\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    "\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8950226f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f9cd8aec8447f9afee7ee658a3c0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1697 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4db9bc2e6e4c24af40f603a864a896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_val = data[\"train\"].train_test_split(\n",
    "    test_size=200, shuffle=True, seed=42\n",
    ")\n",
    "train_data = (\n",
    "    train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    ")\n",
    "val_data = (\n",
    "    train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b1f1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT= 0.05\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"q_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MICRO_BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "LEARNING_RATE = 3e-4\n",
    "TRAIN_STEPS = 300\n",
    "OUTPUT_DIR = \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f2d44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alourido/anaconda3/envs/alpaca/lib/python3.11/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_int8_training(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a676b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
