{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe699a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t  llama-cpp-python     promts.log   requirements.txt\r\n",
      "Error_intall.log  llama_models\t       prueba_2.py  samples\r\n",
      "fintuning.ipynb   llama_promt_log.txt  prueba_3.py  tranfor_data.py\r\n",
      "get_file.py\t  model\t\t       prueba.py    version.md\r\n",
      "llama\t\t  not_git\t       README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45c34a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Título', 'Cuerpo', 'ground_truth'])\n",
      "Título: VisComp Papers\n",
      "\n",
      "Cuerpo: Date: Thu, 21 Nov 1996 20:09:30 GMT Server: NCSA/1.5 Content-type: text/html Last-modified: Thu, 24 Aug 1995 08:39:01 GMT Content-length: 4395 VisComp Papers Ramesh Jain Director Visual Computing Laboratory University of California, San Diego 9500 Gilman Drive, Mail Code 0407 La Jolla, CA 92093-0407 Ramesh Jain is currently a Professor of Electrical and Computer Engineering , and Computer Science and Engineering at University of California, San Diego . Before joining UCSD, he was a Professor of Electrical Engineering and Computer Science , and the founding Director of the Artificial Intelligence Laboratory at the University of Michigan , Ann Arbor , MI . He has also been affiliated with Stanford University , IBM Almaden Research Labs , General Motors Research Labs, Wayne State University , University of Texas at Austin , University of Hamburg , Germany , and Indian Institute of Technology, Kharagpur , India . His current research interests are in multimedia information systems image databases, machine vision , and intelligent systems. He was the founder and the Chairman of Imageware Inc. , an Ann Arbor based company dedicated to revolutionize software interfaces for emerging sensor technologies. He is the founding chairman of Virage , a San Diego based company developing systems for visual information retrieval . Ramesh is a Fellow of IEEE , AAAI , and Society of Photo-Optical Instrumentation Engineers , and member of ACM , Pattern Recognition Society, Cognitive Science Society, Optical Society of America, and Society of Manufacturing Engineers . He has been involved in organization of several professional conferences and workshops, and served on editorial boards of many journals. Currently, he is the Editor-in-Chief of IEEE Multimedia , and is on the editorial boards of Machine Vision and Applications, Pattern Recognition, and Image and Vision Computing. He received his Ph.D. from IIT, Kharagpur in 1975 and his B.E. from Nagpur University in 1969. Arun Katkere Thu Aug 24 01:31:19 PDT 1995\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def get_file(path_file):\n",
    "    with open(path_file) as f:\n",
    "        data = json.load(f)\n",
    "    print(data.keys())\n",
    "    return ('\\n\\n').join([f\"{str(key)}: {data[key]}\" for key in data.keys() if key != 'ground_truth'])\n",
    "    \n",
    "print(get_file('./data/dummy.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c79a36",
   "metadata": {},
   "source": [
    "Intalamos las dependencias necesarias\n",
    "\n",
    "- transformers: for loading a large language model and fine-tuning it.\n",
    "\n",
    "- bitsandbytes: for loading the model in 4-bit precision.\n",
    "\n",
    "- accelerate: for training models and performing inference at scale.\n",
    "\n",
    "- peft: for fine-tuning a small number of parameters.\n",
    "\n",
    "- trl: for training transformer language models using Reinforcement Learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94339b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q accelerate==0.21.0 --progress-bar off\n",
    "!pip install -q peft==0.4.0 --progress-bar off\n",
    "!pip install -q bitsandbytes==0.40.2 --progress-bar off\n",
    "!pip install -q transformers==4.31.0 --progress-bar off\n",
    "!pip install -q trl==0.4.7 --progress-bar off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f29bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32e71ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scipy --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ba59964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                    2.1.0\r\n",
      "torchaudio               2.1.0\r\n",
      "torchvision              0.16.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep tor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e49bf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/alourido/Desktop/alpaca-classification',\n",
       " '/home/alourido/anaconda3/lib/python311.zip',\n",
       " '/home/alourido/anaconda3/lib/python3.11',\n",
       " '/home/alourido/anaconda3/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/home/alourido/anaconda3/lib/python3.11/site-packages']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab167dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva lista de directorios\n",
    "new_sys_path = [\n",
    "    '',\n",
    "    '/home/alourido/anaconda3/envs/alpaca/lib/python311.zip',\n",
    "    '/home/alourido/anaconda3/envs/alpaca/lib/python3.11',\n",
    "    '/home/alourido/anaconda3/envs/alpaca/lib/python3.11/lib-dynload',\n",
    "    '/home/alourido/anaconda3/envs/alpaca/lib/python3.11/site-packages',\n",
    "    '/home/alourido/Desktop/llama'\n",
    "]\n",
    "\n",
    "# Reemplaza sys.path con la nueva lista de directorios\n",
    "sys.path = new_sys_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ece62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8bcaf",
   "metadata": {},
   "source": [
    "A continuación, cargaremos las bibliotecas necesarias para ajustar un modelo de lenguaje grande (LLM) como Llama 2. Examinaremos cada clase importada con mayor detalle en las secciones siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126c92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randrange\n",
    "from functools import partial\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoTokenizer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          HfArgumentParser,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          EarlyStoppingCallback,\n",
    "                          pipeline,\n",
    "                          logging,\n",
    "                          set_seed)\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, AutoPeftModelForCausalLM\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb95f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d311e3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1xQ89cpZCnafsW5T3G3ZQWvR7q682t2BN\n",
      "To: /home/alourido/Desktop/alpaca-classification/bitcoin-sentiment-tweets.csv\n",
      "100%|█████████████████████████████████████████| 242k/242k [00:00<00:00, 379kB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gdown --progress-bar off\n",
    "!gdown 1xQ89cpZCnafsW5T3G3ZQWvR7q682t2BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5854e22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Mar 23 00:40:40 +0000 2018</td>\n",
       "      <td>@p0nd3ea Bitcoin wasn't built to live on excha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Mar 23 00:40:40 +0000 2018</td>\n",
       "      <td>@historyinflicks Buddy if I had whatever serie...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Mar 23 00:40:42 +0000 2018</td>\n",
       "      <td>@eatBCH @Bitcoin @signalapp @myWickr @Samsung ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Mar 23 00:41:04 +0000 2018</td>\n",
       "      <td>@aantonop Even if Bitcoin crash tomorrow morni...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Mar 23 00:41:07 +0000 2018</td>\n",
       "      <td>I am experimenting whether I can live only wit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date  \\\n",
       "0  Fri Mar 23 00:40:40 +0000 2018   \n",
       "1  Fri Mar 23 00:40:40 +0000 2018   \n",
       "2  Fri Mar 23 00:40:42 +0000 2018   \n",
       "3  Fri Mar 23 00:41:04 +0000 2018   \n",
       "4  Fri Mar 23 00:41:07 +0000 2018   \n",
       "\n",
       "                                               tweet  sentiment  \n",
       "0  @p0nd3ea Bitcoin wasn't built to live on excha...        1.0  \n",
       "1  @historyinflicks Buddy if I had whatever serie...        1.0  \n",
       "2  @eatBCH @Bitcoin @signalapp @myWickr @Samsung ...        0.0  \n",
       "3  @aantonop Even if Bitcoin crash tomorrow morni...        0.0  \n",
       "4  I am experimenting whether I can live only wit...        1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data='./data/bitcoin-sentiment-tweets.csv'\n",
    "df = pd.read_csv(path_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "102c9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score_to_name(score: float):\n",
    "    if score > 0:\n",
    "        return \"Positive\"\n",
    "    elif score < 0:\n",
    "        return \"Negative\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "dataset_data = [\n",
    "    {\n",
    "        \"instruction\": \"Detect the sentiment of the tweet.\",\n",
    "        \"input\": row_dict[\"tweet\"],\n",
    "        \"output\": sentiment_score_to_name(row_dict[\"sentiment\"])\n",
    "    }\n",
    "    for row_dict in df.to_dict(orient=\"records\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29d93e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Detect the sentiment of the tweet.',\n",
       " 'input': \"@p0nd3ea Bitcoin wasn't built to live on exchanges.\",\n",
       " 'output': 'Positive'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ab8c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4244010",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m BASE_MODEL \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m LlamaForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      4\u001b[0m     BASE_MODEL,\n\u001b[1;32m      5\u001b[0m     load_in_8bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m      7\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m LlamaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(BASE_MODEL)\n\u001b[1;32m     12\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# unk. we want this to be different from the eos token\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.11/site-packages/transformers/modeling_utils.py:2842\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2838\u001b[0m         device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2839\u001b[0m             key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m modules_to_not_convert\n\u001b[1;32m   2840\u001b[0m         }\n\u001b[1;32m   2841\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m-> 2842\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2843\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;124;03m                Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\u001b[39;00m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;124;03m                the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;124;03m                these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\u001b[39;00m\n\u001b[1;32m   2847\u001b[0m \u001b[38;5;124;03m                `device_map` to `from_pretrained`. Check\u001b[39;00m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;124;03m                https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;124;03m                for more details.\u001b[39;00m\n\u001b[1;32m   2850\u001b[0m \u001b[38;5;124;03m                \"\"\"\u001b[39;00m\n\u001b[1;32m   2851\u001b[0m             )\n\u001b[1;32m   2852\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m device_map_without_lm_head\n\u001b[1;32m   2854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: \n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        "
     ]
    }
   ],
   "source": [
    "BASE_MODEL =  \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit_fp32_cpu_offload=True,\n",
    ")\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "tokenizer.pad_token_id = (\n",
    "    0  # unk. we want this to be different from the eos token\n",
    ")\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1287a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
