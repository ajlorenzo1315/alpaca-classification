{
    "TÃ­tulo": " JPEG Encoding Using Perceptual Quality ",
    "Cuerpo": "Introduction The key point of image compression is to achieve a low bit rate in the digital representation of an input image or video signal with minimum perceived loss of picture quality. But because only one QT is available for every image, the default QT is image independent and can not be used to achieve the optimized compression result for each specific image. Because JPEG allows only one QT for each image, pre-quantization is proposed by Johnston and Safranek(J&S)[1]. Then one base QT will be finally used to quantize for all the remaining coefficients in each block. This problem can be overcome by applying the contrast masking model for each DCT coefficient(model-1). This led us to design a second one(model-2) based on the luminance ratio of block to total image to replace the J&S model. The step of the quantization is to take the raw output of the DCT and quantize the coefficients by dividing it, coefficient by coefficient, by QT, and rounding to the nearest integer. They assume that the total masking level for any block of the input can be represented as a base masking level, and other multiplicative elevation factors that represent the contribution of input dependent properties of the visual system to the total mask. At this point, the DCT coefficients are input to the perceptual model which generates the data dependent quantization table for that block. Our Models Our models intends to take advantage of the above prequantization method. 3.1 Model-1 The J&S's model uses the perceptual model but does not consider the distribution of the energy within the block when calculating the block-specific masking threshold. To overcome this problem, we employ a visual masking that has been widely used in vision models, based on work by Legge and Foley[2]. As a Global masking level, we used default JPEG QT. But for the calculation of multiplicative elevation factors (Local(u,v)), we use the luminance ratio of each block to the total image. At a given luminance f, if the block's luminance is only a little bit differ from luminance f, then the block is less visible and we can drop a lot of perceptually unimportant information. The adaptation is derived as a function of the ratio of the block's average luminance to the luminance average of the total image using the following formula: ---(5) Figure 3. model 2: masking model based on luminance ratio Maximum threshold elevation \"max_e\" and Minimum Threshold (Minimum luminance ratio) \"min_t\" are the parameters we need to experiment for. As a Global masking level, we used default JPEG QT. Image Quality and Bitrate We compared the bitrate(bits/pixel) and Image quality of our model-1 and model-2 with those of the Baseline JPEG. Figure 4 shows one example (\"flowers\") of output image of our models in comparison with original image and that of Baseline JPEG. [3]A.J.Ahumada and H.A.Peterson, \"Luminance-Model-Based DCT quantization for color image compression\", SPIE:Human Vision, Visual Processing, and Digital Display III, Vol.1666,1992, PP365 - 374.",
    "ground_truth": "other"
}