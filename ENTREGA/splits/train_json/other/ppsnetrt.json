{
    "TÃ­tulo": "Papers",
    "Cuerpo": "MIME-Version: 1.0 Server: CERN/3.0 Date: Monday, 06-Jan-97 22:41:20 GMT Content-Type: text/html Content-Length: 6223 Last-Modified: Monday, 12-Aug-96 18:54:14 GMT Papers To view a paper, click on the open book image. Bayesian networks provide a mathematically sound formalism for representing and reasoning with uncertain knowledge and are as such widely used. While the problem of learning a Bayesian network, given complete data, has been explored in some depth, the problem of learning networks with unobserved causes is still open. In this proposal, we view this problem from the perspective of theory revision and present a novel approach which adapts techniques developed for revising theories in symbolic and connectionist representations. Our technique inductively revises the network to fit the data better. Our proposed system has two components: one component revises the parameters of a Bayesian network of known structure, and the other component revises the structure of the network. The component for parameter revision maps the given Bayesian network into a multi-layer feedforward neural network, with the parameters mapped to weights in the neural network, and uses standard backpropagation techniques to learn the weights. The first component has been implemented and we will present results from experiments on real world classification problems which show our technique to be effective. We will also discuss our proposed structure revision algorithm, our plans for experiments to evaluate the system, as well as some extensions to the system. Revising Bayesian Network Parameters Using Backpropagation Sowmya Ramachandran and Raymond J. Mooney To appear in the Proceedings of the International Conference on Neural Networks (ICNN-96), Washington, D.C., June 1996, Special Session on Knowledge-Based Artificial Neural Networks. The problem of learning Bayesian networks with hidden variables is known to be a hard problem. In this paper, we present an approach that learns the conditional probabilities on a Bayesian network with hidden variables by transforming it into a multi-layer feedforward neural network (ANN). Qualitative Modeling & Diagnosis Learning Qualitative Models for Systems with Multiple Operating Regions Sowmya Ramachandran, Raymond J. Mooney and Benjamin J. Kuipers Proceedings of the Eight International Workshop of Qualitative Reasoning about Physical Systems , pp. (QR-94) The problem of learning qualitative models of physical systems from observations of its behaviour has been addressed by several researchers in recent years. Most current techniques limit themselves to learning a single qualitative differential equation to model the entire system. However, many systems have several qualitative differential equations underlying them. In this paper, we present an approach to learning the models for such systems. The qualitative model for each segment can be generated using any of the existing techniques for learning a single model. We show that results of applying our technique to several examples and demonstrate that it is effective. In this paper, we present Information Based Skeletonisation (IMBS), a new approach to this problem where superfluous hidden units are removed based on their information measure (IM).",
    "ground_truth": "other"
}