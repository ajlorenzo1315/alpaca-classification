{
    "TÃ­tulo": "CS 537 - Processes, Part III (Implementation) ",
    "Cuerpo": "It so happens that this is not a problem for the way we will use semaphores to implement monitors. When a process signals or notifies a condition variable on which some other process is waiting, we have a problem: We can't both of the processes immediately continue, since that would violate the cardinal rule that there may never be more than one process active in methods of the same monitor object at the same time. Even if the waiting process is running on its own CPU, this busy waiting may slow down other processes, since it is repeatedly accessing shared memory, thus interfering with accesses to that memory by other CPU's (a shared memory unit can only respond to one CPU at a time). If there is only one CPU, the problem is even worse: Because the process calling down() is running, another process that wants to call up() may not get a chance to run. Since we will only used critical sections to protect short operations (see the implementation of semaphores above ), it is reasonable to assume that a process that has done begin_cs will soon do end_CS , but the converse is not true:  There's no reason to assume that the other process will want to enter its critical section any time in the near future (or even at all!). To get around this problem, a second attempt to solve the problem uses a shared array critical to indicate which processes are in their critical sections. All we have to do is make sure that the short-term scheduler (to be discussed in the next section) does not switch processes while a process is in a critical section. This switching among runnable processes is called short-term scheduling 1 , and the algorithm that decides which process to run and how long to run it is called a short-term scheduling policy or discipline . Since we are concentrating on short-term (CPU) scheduling, one useful way to look at a process is as a sequence of bursts . Each burst is the computation done by a process between the time it becomes ready and the next time it blocks. The scheduler simply runs the first job on the queue until it blocks, then it runs the new first job, and so on. In general, we would like to favor I/O-bound processes, since if we give the CPU to an I/O-bound process, it will quickly finish its burst, start doing some I/O, and get out of the ready list. Suppose we have a set of bursts ready to run and we run them in some order other than SJF. Here's our previous example with SJF scheduling Burst Start Time Finish Time Waiting Time Penalty Ratio A 0 3 0 1.0 B 5 10 4 1.4 C 3 5 0 1.0 D 10 15 1 1.2 E 15 20 3 1.6 Average 1.6 1.24 Here's the Gantt chart : As described, SJF is a non-preemptive policy. There's only one problem with SJF (or SRTF): We don't know how long a burst is going to be until we run it! Thus we might guess that each burst will be the same length as the previous burst of the same process. But after a length of time q (called a quantum ), if the current burst hasn't completed, it is moved to the tail of the queue and the next burst is started. With q = 4 , we get an average waiting time of 3.6 and an average penalty ratio of 1.98 (work it out yourself!). Priority Scheduling There are a whole family of scheduling algorithms that use priorities . For example, priorities can be used to prevent starvation:  If we raise the priority of a burst the longer it has been in the ready queue, eventually it will have the highest priority of all ready burst and be guaranteed a chance to finish.",
    "ground_truth": "other"
}