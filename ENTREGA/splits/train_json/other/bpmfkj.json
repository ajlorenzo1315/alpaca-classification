{
    "TÃ­tulo": "CS 537 - Memory Management",
    "Cuerpo": "In general, a memory manager provides two operations: Address allocate(int size); void deallocate(Address block); The procedure allocate receives a request for a contiguous block of size bytes of memory and returns a pointer to such a block. Suppose there are n processes in memory (this is called the level of multiprogramming ) and each process is blocked (waiting for I/O) a fraction p of the time. To satisfy a deallocate request, the memory manager turns the returned block into a ``hole'' data structure and inserts it into the appropriate place in the free list. The allocate routine returns a pointer to the body of the block, not the header, so the client doesn't need to know about it. For example, the memory mangager may round all requests up to the next power of two bytes (with a minimum of, say, 64) and then keep lists of holes of size 64, 128, 256, ..., etc. This approach eliminates external fragmentation entirely, but internal fragmenation may be as bad as 50% in the worst case (which occurs when all requests are one byte more than a power of two). The system is initialized by splitting memory up into a fixed set of holes (either all the same size or a variety of sizes). An interesting trick for coalescing holes with multiple free lists is the buddy system . Assume all blocks and holes have sizes which are powers of two (so requests are always rounded up to the next power of two) and each block or hole starts at an address that is an exact multiple of its size. Then each block has a ``buddy'' of the same size adjacent to it, such that combining a block of size 2 n with its buddy creates a properly aligned block of size 2 n+1 For example, blocks of size 4 could start at addresses 0, 4, 8, 12, 16, 20, etc. The blocks at 4 and 8 are not buddies even though they are neighbors: Combining them would give a block of size 8 starting at address 4, which is not a multiple of 8. To allocate a block of a given size, first round the size up to the next power of two and look on the list of blocks of that size. If that list is empty, split a block from the next higher list (if that list is empty, first add two blocks to it by splitting a block from the next higher list, and so on). Garbage collection finds blocks of memory that are inaccessible and returns them to the free list. This approach is only practical in situations where there is some ``higher level'' software to keep track of the counts (it's much too hard to do by hand), and even then, it will not detect cyclic structures of garbage: Consider a cycle of blocks, each of which is only pointed to by its predecessor in the cycle. In a batch system, if the OS cannot allocate memory to start a new job, it can ``recover'' by simply delaying starting the job. If there is a queue of jobs waiting to be created, the OS might want to go down the list, looking for a smaller job that can be created right away. Of course we want to use the ``best'' hole for each job (the smallest free partition that is at least as big as the job), but suppose the next job in line is small and all the small partitions are currently in use. When a job is blocked (either because it wants to do I/O or because our short-term scheduling algorithm says to switch to another job), we have a choice of leaving it in memory or swapping it out. One way of looking at this scheme is that it increases the multiprogramming level (the number of jobs ``in memory'') at the cost of making it ( much ) more expensive to switch jobs.",
    "ground_truth": "other"
}