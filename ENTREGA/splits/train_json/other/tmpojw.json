{
    "TÃ­tulo": "Theory Refinement",
    "Cuerpo": "Beginning with a set of certainty-factor rules, along with accurately-labelled training examples, RAPTURE makes use of both symbolic and connectionist learning techniques for revising the rules, in order that they correctly classify all of the training examples. A modified version of backpropagation is used to adjust the certainty factors of the rules, ID3's information-gain heuristic is used to add new rules, and the Upstart algorithm is used to create new hidden terms in the rule base. The first component has been implemented and we will present results from experiments on real world classification problems which show our technique to be effective. (AAAI-96) Theory refinement systems developed in machine learning automatically modify a knowledge base to render it consistent with a set of classified training examples. This approach has been implemented as a computer program, ASSERT, using a machine learning technique called theory refinement , which is a method for automatically revising a knowledge base to be consistent with a set of examples. Revising Bayesian Network Parameters Using Backpropagation Sowmya Ramachandran and Raymond J. Mooney Proceedings of the International Conference on Neural Networks (ICNN-96) , Special Session on Knowledge-Based Artificial Neural Networks, Washington DC, June 1996. This approach has been implemented as a computer program, ASSERT, using a machine learning technique called theory refinement which is a method for automatically revising a knowledge base to be consistent with a set of examples. The first method, implemented in the RAPTURE system, employs neural-network training to refine the certainties of existing rules but uses a symbolic technique to add new rules. The goal of a theory refinement learner is to modify an incomplete or incorrect rule base, representing a domain theory, to make it consistent with a set of input training examples. This paper presents a major revision of the EITHER propositional theory refinement system. To demonstrate the advantages of NEITHER, we present experimental results from two real-world domains. A new student modeling system called ASSERT is described which uses domain independent learning algorithms to model unique student errors and to automatically construct bug libraries. (IJCAI-93) This paper presents a major revision of the EITHER propositional theory refinement system. The task of automatically improving an existing knowledge base using learning methods is addressed by a new class of systems performing theory refinement . Combining Symbolic and Neural Learning to Revise Probabilistic Theories J. Jeffrey Mahoney & Raymond J. Mooney Proceedings of the 1992 Machine Learning Workshop on Integrated Learning in Real Domains , Aberdeen Scotland, July 1992. By combining such diverse methods, EITHER is able to handle a wider range of imperfect theories than other theory revision systems while guaranteeing that the revised theory will be consistent with the training data. Examples of the technique are presented and experimental results are given. This paper presents a method for revising an approximate domain theory based on noisy data. This method is implemented in the EITHER propositional Horn-clause theory revision system. In other words, when the data is noisy, performance on novel test data is considerably better than revising the theory to completely fit the data.",
    "ground_truth": "other"
}