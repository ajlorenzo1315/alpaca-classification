{
    "TÃ­tulo": "\nThe Tower of Pizzas\n",
    "Cuerpo": "Date: Wed, 20 Nov 1996 19:41:24 GMT Server: Apache-SSL/0.4.3b Content-type: text/html Content-length: 4121 Last-modified: Mon, 25 Sep 1995 16:10:40 GMT The Tower of Pizzas The Tower of Pizzas Researchers Dr. Nick Roussopoulos , Principal Investigator Michael Tan , Graduate Student Stephen Kelley , Research Associate Description We have constructed the Tower of Pizzas (TOPs), a multi-user, striped storage system. The main goals of TOPs are 1) to provide access to data striped across workstations, 2) to exploit caching and prefetching at the client and server, 3) to implement the system at a high-level for portability, 4) to explore data layout. The system is implemented in software on top of general UNIX This allows workstations of heterogeneous flavors of UNIX to work together as clients and servers. Server workstations run a single server process, and clients talk to remote servers through a local server process or through a linked library. The local and remote server process are identical, which allows TOPS to be run as a peer-to-peer collection of workstations (rather than just a partitioned set of clients and servers). The local and remote server processes provide buffer management, striping (configurable per file) over the network, and disk services (including asynchronous read/write). We are also examining new data placement techniques. Performance In the three tests below, 1 to 10 clients are run using 1 to 8 servers (srvs). The y-axis gives the total system throughput (the sum of the throughput delivered to each client). Note that the filesystem and disks used for these tests can transfer data at 3.5 MB/s for sequential reads and about 1 MB/s for random reads. Reading cached server data. In this test, clients read from a small file (8 MB/server). The file is completely cached at the server, so no disk I/O (other than the initial load from disk) is incurred. In this test, each client read sequentially through a large file. The portions of the file read by each client was disjoint from one another. We used a prefetching strategy to maintain sequential access to the disk (the requests from the clients were not synchronized). Reading from large disk files. In these tests, each client continually requested a small contiguous portion of the data file. The data file was relatively large (160 MB per server, and could not be entirely cached. Last updated on Fri September 21 12:01 1995",
    "ground_truth": "unknown"
}