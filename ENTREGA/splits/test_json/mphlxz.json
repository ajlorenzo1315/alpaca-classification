{
    "TÃ­tulo": " Virtual Prototyping of Mechanical Assemblies ",
    "Cuerpo": "The result will be an environment in which part interactions can be considered in a more natural manner than is possible with current technology. Assembly procedures can be evaluated at the time when parts are designed, without the need to explicitly specify assembly sequences or constraints. Faculty John M. Hollerbach , PI Elaine Cohen Stephen C. Jacobsen William B. Thompson Staff Russ Fish Graduate Students Rodney Freier David Johnson Ali Nahvi Donald Nelson Thomas Thompson CAD systems for all but the simplest of mechanical parts must be able to provide the designer with a clear sense of three-dimensional object geometry. Usually this is done with standard graphical rendering techniques involving perspective, shading, and simple animation. When such tools are used for assemblies of parts, we often hear designers complain:  ``What I really want to do is get my hands on the parts and see how they fit together.'' In fact what is happening is that the conventional display technologies are not providing the user with sufficient information about the geometry and manipulability of the objects in question. The Sarcos Dextrous Arm Master represents arguably the most advanced force-reflecting exoskeleton available today. In the hand, there is a two degree-of-freedom thumb, a fixed forefinger, and a one degree-of-freedom flexing index/middle finger. The engine involves complex and interrelated part motions that should be well understood by designers prior to committing to expensive fabrication operations. A full-function virtual prototyping system will let the designer manipulate individual parts to see how the entire assembly moves. Virtual prototyping furthermore would allow a designer to consider possible assembly sequences, modifying parts as necessary to ease the assembly process. Finally, a virtual prototyping system with a sufficiently complete model of the human body could be used to validate assembly operations for the engine. Creating a user interface for virtual prototyping systems involves solving three largely independent problems: Visual rendering involves creating realistic views of a configuration of parts. There are two aspects to haptic rendering . Contact and interference computations are needed to determine part-to-part and user-to-part interactions in the virtual world. Visual rendering, haptic rendering, and contact and interference detection must all exploit knowledge about the nature of mechanical assemblies, since general solutions are not likely to be viable. Not only must it be possible to design and render individual parts, but part interactions involving contact, forces, and torques must be computable in real-time. When a designer reaches out to ``grab'' a (virtual) part, the system needs to know when contact with the part has been made so that appropriate feedback can be generated. For those assemblies capable of articulation, a manipulation of one part of the assembly must both cause the appropriate motions in other parts of the assembly and reflect appropriate sensations to the user. Standard CAD systems are unable to supply much of the information needed to support either assembly operations themselves or the haptic rendering required in a virtual prototyping system.",
    "ground_truth": "unknown"
}